{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aaeca595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import traceback\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from openpyxl import load_workbook \n",
    "import config as cfg\n",
    "import eda_tools as tls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a5b085",
   "metadata": {},
   "source": [
    "load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c351b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration load\n",
    "log_path = Path(Path.cwd().parent /  r\"config/config.json\")\n",
    "if not log_path.exists(): \n",
    "    print(f\"Arquivo de configura√ß√£o n√£o encontrado !\\n{log_path}\")\n",
    "    sys.exit(1)\n",
    "log = cfg.config_log(log_path)\n",
    "cfg.load_config() \n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff961700",
   "metadata": {},
   "source": [
    "load sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b8adaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets dfs\n",
    "\n",
    "df_tables = pd.read_excel(cfg.eda_sheet_full_path,sheet_name='tables')\n",
    "df_fields = pd.read_excel(cfg.eda_sheet_full_path,sheet_name='fields', header=1)\n",
    "df_fields = df_fields.astype('object')\n",
    "df_fields.set_index([\"table\", \"field\"], inplace=True)\n",
    "\n",
    "# format headers\n",
    "df_tables.columns = df_tables.columns.str.strip().str.lower()\n",
    "df_fields.columns = df_fields.columns.str.strip().str.lower()\n",
    "\n",
    "# open sheet\n",
    "try:\n",
    "    wb = load_workbook(cfg.eda_sheet_full_path)\n",
    "    tables_sheet = wb[\"tables\"]\n",
    "    fields_sheet = wb[\"fields\"]\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro ao abrir planilhas\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4f443",
   "metadata": {},
   "source": [
    "collect describes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29d1d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ses_cias-----\n",
      "-----ses_ramos-----\n",
      "-----ses_seguros-----\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "<NA>\n",
      "200009\n",
      "100009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "200009\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "110001\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n",
      "199501\n"
     ]
    }
   ],
   "source": [
    "# Estatisticas de contagem por tipo de conteudo do campo \n",
    "from numpy import dtype\n",
    "\n",
    "\n",
    "df_stats = pd.DataFrame(columns=['table','field','stat','value'])\n",
    "stats_collected = []\n",
    "for index, table in df_tables.iterrows():\n",
    "    # load_data\n",
    "    table_name = table['table']\n",
    "    print(f\"-----{table_name}-----\")\n",
    "    data_path = Path(cfg.data_file_path / table['file'])\n",
    "    df_dados = pd.read_csv(data_path,encoding=tls.encode(data_path),quotechar=None,quoting=3,keep_default_na=True,sep=cfg.csv_sep,engine='python',dtype={'damesano': 'str'})\n",
    "    df_dados.columns = df_dados.columns.str.strip().str.lower()\n",
    "    table_count = len(df_dados)\n",
    "\n",
    "    # Counts by content type \n",
    "    df_types = df_dados.map(tls.classify_content)\n",
    "    df_types.apply(pd.Series.value_counts)\n",
    "\n",
    "    for field in df_types.columns:\n",
    "        counts = df_types[field].value_counts(dropna=False)\n",
    "        for stat, value in counts.items():\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field, \"stat\": stat, \"value\": int(value)})\n",
    "\n",
    "    # describe stats\n",
    "    df_fields_table = df_fields.reset_index()\n",
    "    df_fields_table = df_fields_table[df_fields_table['table'] == table_name]\n",
    "    for idx, fld in df_fields_table.iterrows(): \n",
    "        field_name = fld['field']\n",
    "        if fld['type'] == \"str\":\n",
    "            field_series = df_dados[field_name]             \n",
    "            field_series = field_series.astype('object')            \n",
    "        else: \n",
    "           field_series = pd.to_numeric(df_dados[field_name], errors='coerce')\n",
    "        # count \n",
    "        stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"count\" , \"value\": table_count})\n",
    "        # min\n",
    "        stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"min\" , \"value\": field_series.min()})\n",
    "        # max \n",
    "        stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": 'max', \"value\": field_series.max()})\n",
    "        # mean \n",
    "        try: \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"mean\", \"value\": field_series.mean()})        \n",
    "        except: \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"mean\", \"value\": \"no number\"})\n",
    "        # std\n",
    "        try:        \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"std\", \"value\": field_series.std()}) \n",
    "        except: \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"std\", \"value\": \"no number\"})    \n",
    "        # nunique    \n",
    "        stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"unique\", \"value\": field_series.nunique()})\n",
    "        # top\n",
    "        try: \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"top\", \"value\": field_series.mode().iloc[0]})\n",
    "        except: \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"top\", \"value\": \"no value\"})\n",
    "        # freq\n",
    "        try: \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"freq\", \"value\": field_series.value_counts().iloc[0]})\n",
    "        except: \n",
    "           stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"freq\", \"value\": \"no value\"})\n",
    "        # q1, q2, q3\n",
    "        try: \n",
    "            q_values = field_series.quantile([0.25, 0.5, 0.75])\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q1(25%)\", \"value\": q_values.iloc[0]})\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q2(50%)\", \"value\": q_values.iloc[1]})\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q3(75%)\", \"value\": q_values.iloc[2]})\n",
    "        except: \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q1(25%)\", \"value\": \"no value\"})\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q2(50%)\", \"value\": \"no value\"})\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q3(75%)\", \"value\": \"no value\"})\n",
    "        # format\n",
    "\n",
    "        try: \n",
    "            if not pd.isna(fld['regex']): \n",
    "                if fld['type'] == 'int': \n",
    "                    field_series_num = pd.to_numeric(field_series, errors='coerce')\n",
    "                    field_series = field_series_num.round(0).astype('Int64')\n",
    "                regex_pattern = fld['regex']\n",
    "                for valor in field_series: \n",
    "                    print(valor) \n",
    "                bool_series = field_series.astype(str).str.strip().str.match(regex_pattern, na=False)\n",
    "                qty_formats = bool_series.sum()\n",
    "                stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_format\", \"value\": qty_formats})                \n",
    "            else: \n",
    "                stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_format\", \"value\": \"no format\"})\n",
    "        except Exception as e:\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info() \n",
    "            print(\"üõë Erro format!\")\n",
    "            print(f\"üìù Tipo de Erro: {type(e).__name__}\")\n",
    "            linha_do_erro = exc_tb.tb_lineno            \n",
    "            print(f\"üëâ Linha do C√≥digo que Gerou o Erro: {linha_do_erro}\")\n",
    "            print(\"\\n--- Traceback Completo ---\")\n",
    "\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_format\", \"value\": \"err\"})\n",
    "        # list\n",
    "        try: \n",
    "            if not pd.isna(fld['list']): \n",
    "                values_lst = fld['list'].split(';')\n",
    "                field_series_str = field_series.astype(str)\n",
    "                bool_series = field_series_str.isin(values_lst)\n",
    "                stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_list\", \"value\": bool_series.sum()})                \n",
    "            else: \n",
    "                stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_list\", \"value\": \"no list\"})                \n",
    "        except Exception as e:\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info() \n",
    "            print(\"üõë Erro list!\")\n",
    "            print(f\"üìù Tipo de Erro: {type(e).__name__}\")\n",
    "            linha_do_erro = exc_tb.tb_lineno            \n",
    "            print(f\"üëâ Linha do C√≥digo que Gerou o Erro: {linha_do_erro}\")\n",
    "            print(\"\\n--- Traceback Completo ---\")\n",
    "\n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_list\", \"value\": \"err\"})\n",
    "        # range \n",
    "        try: \n",
    "            if fld['type'] == \"int\" or fld['type'] == \"float\":\n",
    "                if not pd.isna(fld['range']): \n",
    "                    \n",
    "                    ranges_list = fld['range']\n",
    "                    range_lst = ranges_list.split(';') \n",
    "                    min_limit_str, max_limit_str = range_lst[0], range_lst[1]\n",
    "                    min_limit = float(min_limit_str)\n",
    "                    max_limit = float(max_limit_str)                    \n",
    "                    field_series_num = pd.to_numeric(field_series, errors='coerce')\n",
    "                    bool_series = field_series_num.between(min_limit, max_limit, inclusive='both')\n",
    "                    qty_range = bool_series.sum()\n",
    "                    stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": qty_range})                \n",
    "                else: \n",
    "                    stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": \"no range\"})\n",
    "            else: \n",
    "                stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": \"no number\"})\n",
    "        except Exception as e: \n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            print(\"üõë Erro range!\")\n",
    "            print(f\"üìù Tipo de Erro: {type(e).__name__}\")\n",
    "            linha_do_erro = exc_tb.tb_lineno            \n",
    "            print(f\"üëâ Linha do C√≥digo que Gerou o Erro: {linha_do_erro}\")\n",
    "            print(\"\\n--- Traceback Completo ---\")\n",
    "            traceback.print_exc()\n",
    "  \n",
    "            stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": \"err\"})    \n",
    "    # stats consolidation     \n",
    "    df_stats = pd.concat([df_stats,pd.DataFrame(stats_collected)])   \n",
    "df_stats = df_stats.astype('object')\n",
    "\n",
    "df_stats_pivot = (df_stats.pivot_table(index=[\"table\",\"field\"], columns=\"stat\", values=\"value\", fill_value=0,aggfunc='first').reset_index())\n",
    "df_stats_pivot_para_update = df_stats_pivot.set_index([\"table\", \"field\"])\n",
    "df_fields.update(df_stats_pivot_para_update)\n",
    "col_list = ['nulls', 'blanks', 'int', 'float', 'str', 'date']\n",
    "df_fields[col_list] = df_fields[col_list].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ae384dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fld = df_fields.reset_index()\n",
    "col_series = df_fld.columns \n",
    "\n",
    "for idx_row, fld_row in df_fld.iterrows(): \n",
    "    line = int(idx_row) + 3\n",
    "    for col_name in col_series: \n",
    "        col = col_series.get_loc(col_name) + 1\n",
    "\n",
    "        fields_sheet.cell(row=line, column=col).value = fld_row[col_name]\n",
    "        # comment_txt = Comment(\"Teste\", \"eda_to_excel\")\n",
    "        # fields_sheet.cell(row=line, column=col).comment = comment_txt\n",
    "\n",
    "wb.save(cfg.eda_sheet_full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-to-exel-rIqPlTpX-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
