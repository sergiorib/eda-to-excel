{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeca595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import traceback\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from openpyxl import load_workbook \n",
    "import config as cfg\n",
    "import eda_tools as tls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a5b085",
   "metadata": {},
   "source": [
    "load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration load\n",
    "log_path = Path(Path.cwd().parent /  r\"config/config.json\")\n",
    "if not log_path.exists(): \n",
    "    print(f\"Arquivo de configura√ß√£o n√£o encontrado !\\n{log_path}\")\n",
    "    sys.exit(1)\n",
    "log = cfg.config_log(log_path)\n",
    "cfg.load_config() \n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff961700",
   "metadata": {},
   "source": [
    "load sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8adaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda dfs create\n",
    "df_tables = pd.read_excel(cfg.eda_sheet_full_path,sheet_name='tables')\n",
    "df_fields = pd.read_excel(cfg.eda_sheet_full_path,sheet_name='fields', header=1)\n",
    "\n",
    "# eda dfs config\n",
    "df_fields = df_fields.astype('object') \n",
    "df_fields.columns = df_fields.columns.str.strip().str.lower()\n",
    "df_tables.columns = df_tables.columns.str.strip().str.lower()\n",
    "\n",
    "# open eda sheet workbooks\n",
    "try:\n",
    "    wb = load_workbook(cfg.eda_sheet_full_path, data_only=False)\n",
    "    tables_workbook = wb[\"tables\"]\n",
    "    fields_workbook = wb[\"fields\"]\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro ao abrir planilhas\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4f443",
   "metadata": {},
   "source": [
    "collect stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create collect structures\n",
    "from eda_tools import file_stats\n",
    "\n",
    "df_table_stats = pd.DataFrame(columns=['table','stat','value'])\n",
    "table_stats_collected = []\n",
    "df_field_stats = pd.DataFrame(columns=['table','field','stat','value'])\n",
    "field_stats_collected = []\n",
    "\n",
    "for index, table in df_tables.iterrows():\n",
    "    table_name = table['table']\n",
    "    print(f\"-----{table_name}-----\")\n",
    "\n",
    "    # load data\n",
    "    data_path = Path(cfg.data_file_path / table['file'])\n",
    "    df_data = pd.read_csv(data_path,encoding=tls.encode(data_path),quotechar=None,quoting=3,keep_default_na=True,sep=cfg.csv_sep,engine='python')\n",
    "    df_data.columns = df_data.columns.str.strip().str.lower()\n",
    "\n",
    "    # ---------  table stats ---------  \n",
    "    file_size, col_count, col_exists, col_unique = file_stats(table_name,df_fields,data_path,cfg.csv_sep)\n",
    "    table_stats_collected.append({\"table\": table_name, \"stat\": \"file_size\", \"value\":file_size})\n",
    "    table_stats_collected.append({\"table\": table_name, \"stat\": \"lines\", \"value\":len(df_data)})\n",
    "    table_stats_collected.append({\"table\": table_name, \"stat\": \"columns\", \"value\":col_count})\n",
    "    table_stats_collected.append({\"table\": table_name, \"stat\": \"columns_existence\", \"value\":col_exists})    \n",
    "    table_stats_collected.append({\"table\": table_name, \"stat\": \"column_unique\", \"value\": col_unique})    \n",
    "\n",
    "    # pk_unique\t\n",
    "    #table_stats_collected.append({\"table\": table_name, \"stat\": stat, \"pk_unique\": })    \n",
    "    \n",
    "    # referencial_integrity\n",
    "    #table_stats_collected.append({\"table\": table_name, \"stat\": stat, \"referencial_integrity\": })\n",
    "\n",
    "    # ---------  fields stats ---------\n",
    "\n",
    "    # Counts by content type \n",
    "    df_types = df_data.map(tls.classify_content)\n",
    "    df_types.apply(pd.Series.value_counts)\n",
    "\n",
    "    for field in df_types.columns:\n",
    "        counts = df_types[field].value_counts(dropna=False)\n",
    "        for stat, value in counts.items():\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field, \"stat\": stat, \"value\": int(value)})\n",
    "\n",
    "    # describe stats\n",
    "    df_fields_by_table = df_fields.reset_index()\n",
    "    df_fields_by_table = df_fields_by_table[df_fields_by_table['table'] == table_name]\n",
    "    for idx, fld in df_fields_by_table.iterrows(): \n",
    "        field_name = fld['field']\n",
    "        if fld['type'] == \"str\":\n",
    "            field_series = df_data[field_name]             \n",
    "            field_series = field_series.astype('object')            \n",
    "        else: \n",
    "           field_series = pd.to_numeric(df_data[field_name], errors='coerce')\n",
    "        # count \n",
    "        field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"count\" , \"value\": len(df_data)})\n",
    "        # min\n",
    "        field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"min\" , \"value\": field_series.min()})\n",
    "        # max \n",
    "        field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": 'max', \"value\": field_series.max()})\n",
    "        # mean \n",
    "        try: \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"mean\", \"value\": field_series.mean()})        \n",
    "        except: \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\": \"mean\", \"value\": \"no number\"})\n",
    "        # std\n",
    "        try:        \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"std\", \"value\": field_series.std()}) \n",
    "        except: \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"std\", \"value\": \"no number\"})    \n",
    "        # nunique    \n",
    "        field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"unique\", \"value\": field_series.nunique()})\n",
    "        # top\n",
    "        try: \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"top\", \"value\": field_series.mode().iloc[0]})\n",
    "        except: \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"top\", \"value\": \"no value\"})\n",
    "        # freq\n",
    "        try: \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"freq\", \"value\": field_series.value_counts().iloc[0]})\n",
    "        except: \n",
    "           field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"freq\", \"value\": \"no value\"})\n",
    "        # q1, q2, q3\n",
    "        try: \n",
    "            q_values = field_series.quantile([0.25, 0.5, 0.75])\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q1(25%)\", \"value\": q_values.iloc[0]})\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q2(50%)\", \"value\": q_values.iloc[1]})\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q3(75%)\", \"value\": q_values.iloc[2]})\n",
    "        except: \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q1(25%)\", \"value\": \"no value\"})\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q2(50%)\", \"value\": \"no value\"})\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"q3(75%)\", \"value\": \"no value\"})\n",
    "        # format\n",
    "        try: \n",
    "            if not pd.isna(fld['regex']): \n",
    "                if fld['type'] == 'int': \n",
    "                    field_series_num = pd.to_numeric(field_series, errors='coerce')\n",
    "                    field_series = field_series_num.round(0).astype('Int64')\n",
    "                regex_pattern = fld['regex']\n",
    "                bool_series = field_series.astype(str).str.strip().str.match(regex_pattern, na=False)\n",
    "                qty_formats = bool_series.sum()\n",
    "                field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_format\", \"value\": qty_formats})                \n",
    "            else: \n",
    "                field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_format\", \"value\": \"no format\"})\n",
    "        except Exception as e:\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info() \n",
    "            print(\"üõë Erro format!\")\n",
    "            print(f\"üìù Tipo de Erro: {type(e).__name__}\")\n",
    "            linha_do_erro = exc_tb.tb_lineno            \n",
    "            print(f\"üëâ Linha do C√≥digo que Gerou o Erro: {linha_do_erro}\")\n",
    "            print(\"\\n--- Traceback Completo ---\")\n",
    "\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_format\", \"value\": \"err\"})\n",
    "        # list\n",
    "        try: \n",
    "            if not pd.isna(fld['list']): \n",
    "                values_lst = fld['list'].split(';')\n",
    "                field_series_str = field_series.astype(str)\n",
    "                bool_series = field_series_str.isin(values_lst)\n",
    "                field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_list\", \"value\": bool_series.sum()})                \n",
    "            else: \n",
    "                field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_list\", \"value\": \"no list\"})                \n",
    "        except Exception as e:\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info() \n",
    "            print(\"üõë Erro list!\")\n",
    "            print(f\"üìù Tipo de Erro: {type(e).__name__}\")\n",
    "            linha_do_erro = exc_tb.tb_lineno            \n",
    "            print(f\"üëâ Linha do C√≥digo que Gerou o Erro: {linha_do_erro}\")\n",
    "            print(\"\\n--- Traceback Completo ---\")\n",
    "\n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_list\", \"value\": \"err\"})\n",
    "        # range \n",
    "        try: \n",
    "            if fld['type'] == \"int\" or fld['type'] == \"float\":\n",
    "                if not pd.isna(fld['range']): \n",
    "                    \n",
    "                    ranges_list = fld['range']\n",
    "                    range_lst = ranges_list.split(';') \n",
    "                    min_limit_str, max_limit_str = range_lst[0], range_lst[1]\n",
    "                    min_limit = float(min_limit_str)\n",
    "                    max_limit = float(max_limit_str)                    \n",
    "                    field_series_num = pd.to_numeric(field_series, errors='coerce')\n",
    "                    bool_series = field_series_num.between(min_limit, max_limit, inclusive='both')\n",
    "                    qty_range = bool_series.sum()\n",
    "                    field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": qty_range})                \n",
    "                else: \n",
    "                    field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": \"no range\"})\n",
    "            else: \n",
    "                field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": \"no number\"})\n",
    "        except Exception as e: \n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            print(\"üõë Erro range!\")\n",
    "            print(f\"üìù Tipo de Erro: {type(e).__name__}\")\n",
    "            linha_do_erro = exc_tb.tb_lineno            \n",
    "            print(f\"üëâ Linha do C√≥digo que Gerou o Erro: {linha_do_erro}\")\n",
    "            print(\"\\n--- Traceback Completo ---\")\n",
    "            traceback.print_exc()\n",
    "  \n",
    "            field_stats_collected.append({\"table\": table_name, \"field\": field_name, \"stat\":\"valid_on_range\", \"value\": \"err\"})    \n",
    "\n",
    "    # stats collected consolidation     \n",
    "    df_field_stats = pd.concat([df_field_stats,pd.DataFrame(field_stats_collected)])   \n",
    "    df_table_stats = pd.concat([df_table_stats,pd.DataFrame(table_stats_collected)])\n",
    "\n",
    "df_field_stats = df_field_stats.astype('object')\n",
    "df_table_stats = df_table_stats.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update fields stats\n",
    "df_field_stats_pivot = (df_field_stats.pivot_table(index=[\"table\",\"field\"], columns=\"stat\", values=\"value\", fill_value=0,aggfunc='first').reset_index())\n",
    "df_field_stats_pivot.set_index([\"table\", \"field\"], inplace=True)\n",
    "df_fields.set_index([\"table\", \"field\"], inplace=True)\n",
    "df_fields.update(df_field_stats_pivot)\n",
    "\n",
    "# update table stats\n",
    "df_table_stats_pivot = (df_table_stats.pivot_table(index=[\"table\"], columns=\"stat\", values=\"value\", fill_value=0,aggfunc='first').reset_index())\n",
    "print(df_table_stats_pivot.head())\n",
    "df_table_stats_pivot.set_index([\"table\"], inplace=True)\n",
    "df_tables.set_index([\"table\"], inplace=True)\n",
    "df_tables.update(df_table_stats_pivot)\n",
    "\n",
    "col_list = ['nulls', 'blanks', 'int', 'float', 'str', 'date']\n",
    "df_fields[col_list] = df_fields[['nulls', 'blanks', 'int', 'float', 'str', 'date']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae384dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update fields workbook\n",
    "df_fields = df_fields.reset_index()\n",
    "col_series = df_fields.columns \n",
    "\n",
    "for idx, field_row in df_fields.iterrows(): \n",
    "    line = int(idx) + 3\n",
    "    for col_name in col_series: \n",
    "        if col_name.startswith(\"unnamed\"):\n",
    "            continue \n",
    "        col = col_series.get_loc(col_name) + 1\n",
    "        fields_workbook.cell(row=line, column=col).value = field_row[col_name]\n",
    "\n",
    "# update table workbook\n",
    "df_tables = df_tables.reset_index()\n",
    "col_series = df_tables.columns \n",
    "for idx, table_row in df_tables.iterrows(): \n",
    "    line = int(idx) + 2\n",
    "    for col_name in col_series: \n",
    "        if col_name.startswith(\"unnamed\"):\n",
    "            continue \n",
    "        col = col_series.get_loc(col_name) + 1\n",
    "        tables_workbook.cell(row=line, column=col).value = table_row[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sheet\n",
    "wb.save(cfg.eda_sheet_full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-to-exel-rIqPlTpX-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
